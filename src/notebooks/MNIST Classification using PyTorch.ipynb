{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213a2f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7173, 0.5319, 0.1682],\n",
      "        [0.4063, 0.2086, 0.9212],\n",
      "        [0.0931, 0.0703, 0.2424],\n",
      "        [0.0771, 0.2875, 0.3451],\n",
      "        [0.9343, 0.8505, 0.3387]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58a6034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Admin/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "!wandb login 6efb86bf60c1e6753f7cd318f46f09fb910b86a8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65991cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b2fd85",
   "metadata": {},
   "source": [
    "### Setup the `device` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f6d3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff9ca0",
   "metadata": {},
   "source": [
    "# Download and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15cf7207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\d\\python\\deep_learning\\env\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))\n",
    "    transforms.ColorJitter()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2711e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a686b60",
   "metadata": {},
   "source": [
    "# Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790976d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ## Conv 1st Block\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b8a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, steps_per_epoch=20):\n",
    "  # Switch model to training mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
    "  model.train()\n",
    "  train_total = 0\n",
    "  train_correct = 0\n",
    "\n",
    "  # We loop over the data iterator, and feed the inputs to the network and adjust the weights.\n",
    "  for batch_idx, (data, target) in enumerate(train_loader, start=0):\n",
    "    if batch_idx > steps_per_epoch:\n",
    "      break\n",
    "    # Load the input features and labels from the training dataset\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    \n",
    "    # Reset the gradients to 0 for all learnable weight parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass: Pass image data from training dataset, make predictions about class image belongs to (0-9 in this case)\n",
    "    output = model(data)\n",
    "    \n",
    "    # Define our loss function, and compute the loss\n",
    "    loss = F.nll_loss(output, target)\n",
    "\n",
    "    scores, predictions = torch.max(output.data, 1)\n",
    "    train_total += target.size(0)\n",
    "    train_correct += int(sum(predictions == target))\n",
    "            \n",
    "    # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the neural network weights\n",
    "    optimizer.step()\n",
    "\n",
    "  acc = round((train_correct / train_total) * 100, 2)\n",
    "  print('Epoch [{}], Loss: {}, Accuracy: {}'.format(epoch, loss.item(), acc), end='')\n",
    "  wandb.log({'Train Loss': loss.item(), 'Train Accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "029cd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, classes):\n",
    "  # Switch model to evaluation mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  test_total = 0\n",
    "  test_correct = 0\n",
    "\n",
    "  example_images = []\n",
    "  with torch.no_grad():\n",
    "      for data, target in test_loader:\n",
    "          # Load the input features and labels from the test dataset\n",
    "          data, target = data.to(device), target.to(device)\n",
    "          \n",
    "          # Make predictions: Pass image data from test dataset, make predictions about class image belongs to (0-9 in this case)\n",
    "          output = model(data)\n",
    "          \n",
    "          # Compute the loss sum up batch loss\n",
    "          test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "          \n",
    "          scores, predictions = torch.max(output.data, 1)\n",
    "          test_total += target.size(0)\n",
    "          test_correct += int(sum(predictions == target))\n",
    "          \n",
    "          # WandB – Log images in your test dataset automatically, along with predicted and true labels by passing pytorch tensors with image data into wandb.Image\n",
    "          # example_images.append(wandb.Image(\n",
    "          #     data[0], caption=\"Pred: {} Truth: {}\".format(classes[pred[0].item()], classes[target[0]])))\n",
    "  acc = round((test_correct / test_total) * 100, 2)\n",
    "  print(' Test_loss: {}, Test_accuracy: {}'.format(test_loss/test_total, acc))\n",
    "  wandb.log({'Test Loss': test_loss, 'Test Accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d5b7d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "print(net)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e3a6311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1cwgii5l) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12144<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\D\\python\\Deep_Learning\\src\\wandb\\run-20210829_133658-1cwgii5l\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\D\\python\\Deep_Learning\\src\\wandb\\run-20210829_133658-1cwgii5l\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">major-wave-1</strong>: <a href=\"https://wandb.ai/aaleksanyan/common-ml-errors/runs/1cwgii5l\" target=\"_blank\">https://wandb.ai/aaleksanyan/common-ml-errors/runs/1cwgii5l</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1cwgii5l). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sandy-snowball-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/aaleksanyan/common-ml-errors\" target=\"_blank\">https://wandb.ai/aaleksanyan/common-ml-errors</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/aaleksanyan/common-ml-errors/runs/xqkhazrn\" target=\"_blank\">https://wandb.ai/aaleksanyan/common-ml-errors/runs/xqkhazrn</a><br/>\n",
       "                Run data is saved locally in <code>c:\\D\\python\\Deep_Learning\\src\\wandb\\run-20210829_133829-xqkhazrn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\d\\python\\deep_learning\\env\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], Loss: 0.7026039361953735, Accuracy: 69.35 Test_loss: 0.5836685862064361, Test_accuracy: 84.11\n",
      "Epoch [1], Loss: 0.32897791266441345, Accuracy: 87.28 Test_loss: 0.34520052094459536, Test_accuracy: 90.17\n",
      "Epoch [2], Loss: 0.2442597895860672, Accuracy: 90.85 Test_loss: 0.21794201847910882, Test_accuracy: 93.71\n",
      "Epoch [3], Loss: 0.29293766617774963, Accuracy: 93.68 Test_loss: 0.1825956507563591, Test_accuracy: 94.58\n",
      "Epoch [4], Loss: 0.06246434524655342, Accuracy: 94.87 Test_loss: 0.1415964467987418, Test_accuracy: 95.88\n",
      "Epoch [5], Loss: 0.1287214457988739, Accuracy: 95.01 Test_loss: 0.15999461981803179, Test_accuracy: 95.41\n",
      "Epoch [6], Loss: 0.14805512130260468, Accuracy: 95.98 Test_loss: 0.1272623852841556, Test_accuracy: 96.02\n",
      "Epoch [7], Loss: 0.15790097415447235, Accuracy: 95.54 Test_loss: 0.11555568621605634, Test_accuracy: 96.63\n",
      "Epoch [8], Loss: 0.04254532605409622, Accuracy: 96.13 Test_loss: 0.10558980406969785, Test_accuracy: 96.83\n",
      "Epoch [9], Loss: 0.05276499688625336, Accuracy: 95.91 Test_loss: 0.09462682169675828, Test_accuracy: 97.14\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5800<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\D\\python\\Deep_Learning\\src\\wandb\\run-20210829_133829-xqkhazrn\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\D\\python\\Deep_Learning\\src\\wandb\\run-20210829_133829-xqkhazrn\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train Loss</td><td>0.05276</td></tr><tr><td>Train Accuracy</td><td>95.91</td></tr><tr><td>_runtime</td><td>30</td></tr><tr><td>_timestamp</td><td>1630229944</td></tr><tr><td>_step</td><td>19</td></tr><tr><td>Test Loss</td><td>946.26822</td></tr><tr><td>Test Accuracy</td><td>97.14</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Train Loss</td><td>█▄▃▄▁▂▂▂▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>_runtime</td><td>▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▆▇▇▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▆▇▇▇█</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>Test Loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>Test Accuracy</td><td>▁▄▆▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">sandy-snowball-2</strong>: <a href=\"https://wandb.ai/aaleksanyan/common-ml-errors/runs/xqkhazrn\" target=\"_blank\">https://wandb.ai/aaleksanyan/common-ml-errors/runs/xqkhazrn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='common-ml-errors')\n",
    "wandb.watch(net, log='all')\n",
    "\n",
    "for epoch in range(10):\n",
    "  train(net, device, trainloader, optimizer, epoch)\n",
    "  test(net, device, testloader, classes)\n",
    "\n",
    "print('Finished Training')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e04737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
